{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_all_files_in_dir(dir_path: str, extension:str = None) -> list[str]:\n",
    "    files = []\n",
    "    for r, d, f in os.walk(dir_path):\n",
    "        for file in f:\n",
    "            if extension is not None and f'.{extension}' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files\n",
    "\n",
    "# get_all_files_in_dir('../data', 'pgn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter games with eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at line 0 for serie data_2014_07\n",
      "Game 0 for serie data_2014_07\n",
      "Game 100000 for serie data_2014_07\n",
      "Game 200000 for serie data_2014_07\n",
      "Game 300000 for serie data_2014_07\n",
      "Game 400000 for serie data_2014_07\n",
      "Game 500000 for serie data_2014_07\n",
      "Game 600000 for serie data_2014_07\n",
      "Game 700000 for serie data_2014_07\n",
      "Game 800000 for serie data_2014_07\n",
      "Game 900000 for serie data_2014_07\n",
      "Game 1000000 for serie data_2014_07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data\\\\filtered_pgn\\\\data_2014_07.pgn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def process_game_rows( game_rows: list[str]) -> list[str]:\n",
    "    if game_rows[0] == '\\n':\n",
    "        game_rows.pop(0)\n",
    "    if game_rows[-1] != '\\n':\n",
    "        game_rows.append('\\n')\n",
    "    return game_rows\n",
    "\n",
    "def save_filtered_data_line_start_index(serie_name: str, index:int):\n",
    "    file_path = '../data/keep_track.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    data[serie_name][\"filtered_data_start_index\"] = index\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "def get_filtered_data_line_start_index(serie_name: str) -> int:\n",
    "    file_path = '../data/keep_track.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if serie_name not in data:\n",
    "        data[serie_name] = {\"filtered_data_start_index\": 0}\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data[serie_name][\"filtered_data_start_index\"]\n",
    "\n",
    "\n",
    "def save_games(games: list[str], save_path: str, mode: str = 'a'):\n",
    "    eval_file = ''.join(games)\n",
    "    with open(save_path, mode) as f:\n",
    "        f.write(eval_file)\n",
    "\n",
    "def reset_file(file_path: str):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write('')\n",
    "\n",
    "def filter_games_with_evaluations(file_path: str, save_folder:str, save_every:int = 10000, print_every:int = 10000):\n",
    "    serie_name = file_path.split('\\\\')[-1].replace('.pgn','') # Nom du fichier sans extension\n",
    "    save_path = save_folder + file_path.split('\\\\')[-1]\n",
    "    eval_games, nb_games, start_index = [], 0, 0\n",
    "    reset_file(save_path)\n",
    "    \n",
    "    print(f\"Starting at line {start_index} for serie {serie_name}\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        game_rows = []\n",
    "        for line_index,line in enumerate(f):\n",
    "            if line_index < start_index:\n",
    "                continue\n",
    "            game_rows.append(line)\n",
    "            if line[0] == '1':\n",
    "                # Si ça commence par 1, c'est la ligne des coups du jeu\n",
    "                if nb_games % print_every == 0:\n",
    "                    print(f\"Game {nb_games} for serie {serie_name}\")\n",
    "                if 'eval' in line:\n",
    "                    # Si le jeu contient des évaluations, on le garde\n",
    "                    game_rows = process_game_rows(game_rows)\n",
    "                    eval_games += game_rows\n",
    "                game_rows = []\n",
    "                if nb_games % save_every == 0:\n",
    "                    # On sauvegarde tous les save_every jeux\n",
    "                    #save_filtered_data_line_start_index(serie_name, line_index)\n",
    "                    save_games(eval_games, save_path, 'a')\n",
    "                    eval_games = []\n",
    "                nb_games += 1\n",
    "    \n",
    "    #save_filtered_data_line_start_index(serie_name, line_index)\n",
    "    save_games(eval_games, save_path, 'a')\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "filter_games_with_evaluations(\"../data\\\\raw_pgn\\\\data_2014_07.pgn\", \"../data\\\\filtered_pgn\\\\\", save_every=10000, print_every=100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each positions of PGN game to FEN into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_games: 200\n",
      "nb_games: 400\n",
      "nb_games: 600\n",
      "nb_games: 800\n",
      "nb_games: 1000\n",
      "nb_games: 1200\n",
      "nb_games: 1400\n",
      "nb_games: 1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data\\\\csv_positions\\\\data_test.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chess.pgn \n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_game(game: chess.pgn.Game, history: list[dict]):\n",
    "    positions = []\n",
    "    while not game.is_end():\n",
    "        game = game.variation(0)\n",
    "        fen = game.board().fen()\n",
    "        eval = game.eval()\n",
    "        if eval is not None:\n",
    "            eval = game.eval().relative.score(mate_score=100000)/100\n",
    "            positions.append({\"fen\": fen, \"eval\": eval})\n",
    "    return positions\n",
    "\n",
    "def save_positions(positions: list[dict], save_path: str, mode: str = 'a'):\n",
    "    if not os.path.isfile(save_path):\n",
    "        mode = 'w'\n",
    "        \n",
    "    with open(save_path, mode, newline='') as csvfile:\n",
    "        fieldnames = ['fen', 'eval']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if mode == 'w':\n",
    "            writer.writeheader()\n",
    "        for position in positions:\n",
    "            writer.writerow(position)\n",
    "\n",
    "def save_csv_line_start_index(serie_name: str, index:int):\n",
    "    file_path = '../data/keep_track.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    data[serie_name][\"csv_positions_start_index\"] = index\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "def get_csv_line_start_index(serie_name: str) -> int:\n",
    "    file_path = '../data/keep_track.json'\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if serie_name not in data:\n",
    "        data[serie_name] = {\"csv_positions_start_index\": 0}\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data[serie_name][\"csv_positions_start_index\"]\n",
    "\n",
    "def convert_pgn_to_csv(file_path: str, save_folder:str, save_every:int = 10000, print_every:int = 10000, limit:int = None):\n",
    "    save_path = save_folder + file_path.split('\\\\')[-1].split('.')[0] + '.csv'\n",
    "    serie_name = file_path.split('\\\\')[-1].replace('.pgn','') # Nom du fichier sans extension\n",
    "    all_positions, nb_games = [], 0\n",
    "    nb_game_start_index = get_csv_line_start_index(file_path.split('\\\\')[-1].split('.')[0])\n",
    "    with open(file_path) as pgn:\n",
    "        while nb_games <= nb_game_start_index:\n",
    "            row = pgn.readline()\n",
    "            if (row == ''): # Fin du fichier\n",
    "                break\n",
    "            if row[0] == '1':\n",
    "                nb_games += 1\n",
    "        while True:\n",
    "\n",
    "            if row == '' or limit is not None and nb_games - nb_game_start_index >= limit:\n",
    "                break\n",
    "\n",
    "            if nb_games % print_every == 0:\n",
    "                print(f\"nb_games: {nb_games}\")\n",
    "\n",
    "            \n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break\n",
    "            positions = process_game(game, all_positions)\n",
    "            all_positions += positions\n",
    "            nb_games += 1\n",
    "            if nb_games % save_every == 0:\n",
    "                save_positions(all_positions, save_path, 'a')\n",
    "                save_csv_line_start_index(serie_name, nb_games)\n",
    "                all_positions = []\n",
    "\n",
    "    save_positions(all_positions, save_path, 'a')\n",
    "    save_csv_line_start_index(serie_name, nb_games)\n",
    "\n",
    "    return save_path\n",
    "\n",
    "convert_pgn_to_csv(\"../data\\\\filtered_pgn\\\\data_test.pgn\", \"../data\\\\csv_positions\\\\\", save_every=100, print_every=200, limit=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_duplicates_in_csv(file_path:str, save_path:str):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop_duplicates(subset=['fen'])\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "remove_duplicates_in_csv(\"../data\\\\csv_positions\\\\data_2013_09.csv\", \"../data\\\\csv_positions\\\\data_2013_09.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(raw_data_folder, filtered_data_folder, csv_folder):\n",
    "    raw_data_file_pathes = get_all_files_in_dir(raw_data_folder, 'pgn')\n",
    "    for file_path in raw_data_file_pathes:\n",
    "        # remove games without evaluations and save to filtered_data_folder\n",
    "        filtered_data_path = filter_games_with_evaluations(file_path, filtered_data_folder, limit=200000)\n",
    "        # convert pgn game positions to csv and save to csv_folder\n",
    "        csv_file_path = convert_pgn_to_csv(filtered_data_path, csv_folder)\n",
    "        # remove fen duplicates in csv file\n",
    "        remove_duplicates_in_csv(csv_file_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_games: 0, nb_games_with_eval: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_games: 10000, nb_games_with_eval: 1743\n",
      "nb_games: 20000, nb_games_with_eval: 3340\n",
      "nb_games: 30000, nb_games_with_eval: 4942\n",
      "nb_games: 40000, nb_games_with_eval: 6594\n",
      "nb_games: 50000, nb_games_with_eval: 8184\n",
      "nb_games: 60000, nb_games_with_eval: 9855\n",
      "nb_games: 70000, nb_games_with_eval: 11419\n",
      "nb_games: 80000, nb_games_with_eval: 13015\n",
      "nb_games: 90000, nb_games_with_eval: 14690\n",
      "nb_games: 100000, nb_games_with_eval: 16329\n",
      "nb_games: 110000, nb_games_with_eval: 17996\n",
      "nb_games: 120000, nb_games_with_eval: 19614\n",
      "nb_games: 130000, nb_games_with_eval: 21309\n",
      "nb_games: 140000, nb_games_with_eval: 22946\n",
      "nb_games: 150000, nb_games_with_eval: 24631\n",
      "nb_games: 160000, nb_games_with_eval: 26259\n",
      "nb_games: 170000, nb_games_with_eval: 28001\n",
      "nb_games: 180000, nb_games_with_eval: 29715\n",
      "nb_games: 190000, nb_games_with_eval: 31341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m filtered_data_folder \u001b[39m=\u001b[39m data_folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiltered_pgn\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m csv_folder \u001b[39m=\u001b[39m data_folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcsv_positions\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m data_pipeline(raw_data_folder, filtered_data_folder, csv_folder)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mdata_pipeline\u001b[1;34m(raw_data_folder, filtered_data_folder, csv_folder)\u001b[0m\n\u001b[0;32m      5\u001b[0m filtered_data_path \u001b[39m=\u001b[39m filter_games_with_evaluations(file_path, filtered_data_folder, limit\u001b[39m=\u001b[39m\u001b[39m200000\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# convert pgn game positions to csv and save to csv_folder\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m csv_file_path \u001b[39m=\u001b[39m convert_pgn_to_csv(filtered_data_path, csv_folder)\n\u001b[0;32m      8\u001b[0m \u001b[39m# remove fen duplicates in csv file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m remove_duplicates_in_csv(csv_file_path, csv_file_path)\n",
      "Cell \u001b[1;32mIn[9], line 45\u001b[0m, in \u001b[0;36mconvert_pgn_to_csv\u001b[1;34m(file_path, save_folder, limit)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m game \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m positions \u001b[39m=\u001b[39m process_game(game, all_positions)\n\u001b[0;32m     46\u001b[0m all_positions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m positions\n\u001b[0;32m     47\u001b[0m \u001b[39m# nb_games_with_eval += 1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mprocess_game\u001b[1;34m(game, history)\u001b[0m\n\u001b[0;32m     11\u001b[0m game \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mvariation(\u001b[39m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m fen \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mboard()\u001b[39m.\u001b[39mfen()\n\u001b[1;32m---> 13\u001b[0m \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39;49meval()\n\u001b[0;32m     14\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39meval\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mis_mate():\n",
      "File \u001b[1;32mc:\\Users\\barry\\OneDrive\\Bureau\\Projects\\chess\\backend\\env\\lib\\site-packages\\chess\\pgn.py:409\u001b[0m, in \u001b[0;36mGameNode.eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39mParses the first valid ``[%eval ...]`` annotation in the comment of\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[39mthis node, if any.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    408\u001b[0m match \u001b[39m=\u001b[39m EVAL_REGEX\u001b[39m.\u001b[39msearch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomment)\n\u001b[1;32m--> 409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match:\n\u001b[0;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    412\u001b[0m turn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mturn()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_folder = \"..\\\\data\\\\\"\n",
    "raw_data_folder = data_folder + \"raw_pgn\\\\\"\n",
    "filtered_data_folder = data_folder + \"filtered_pgn\\\\\"\n",
    "csv_folder = data_folder + \"csv_positions\\\\\"\n",
    "\n",
    "data_pipeline(raw_data_folder, filtered_data_folder, csv_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
